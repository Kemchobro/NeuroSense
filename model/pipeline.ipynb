{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31398cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install libraries\n",
    "!pip install praat-parselmouth librosa scikit-learn imbalanced-learn shap tqdm tensorflow==2.20.0 pillow\n",
    "!pip install mlxtend\n",
    "!pip install onnx onnx-tf\n",
    "!pip install tensorflow\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5fba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec50454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "#start config\n",
    "BASE_DIR = r\"C:\\Users\\vidha\\Documents\\congressionalapp\\model\"\n",
    "DATASET_DIR = os.path.join(BASE_DIR, \"voice_dataset\")\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"spectrograms_melfixed\") \n",
    "SAMPLE_RATE = 22050\n",
    "N_MELS = 128\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "#helpers\n",
    "def save_spectrogram(file_path, label_prefix, index):\n",
    "    try:\n",
    "        print(f\"Loading {file_path}\")\n",
    "        y, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "        if len(y) == 0:\n",
    "            print(f\"Empty audio: {file_path}\")\n",
    "            return\n",
    "\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS)\n",
    "        mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        librosa.display.specshow(mel_db, sr=sr, cmap='magma')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout(pad=0)\n",
    "\n",
    "        output_name = f\"{label_prefix}_{index:04d}.png\"\n",
    "        output_path = os.path.join(OUTPUT_DIR, output_name)\n",
    "        plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "        print(f\"Saved: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "#,aom\n",
    "labels = {\"PD_AH\": \"PD\", \"HC_AH\": \"HC\"}\n",
    "counter = {\"PD\": 0, \"HC\": 0}\n",
    "\n",
    "for subfolder, label_prefix in labels.items():\n",
    "    folder_path = os.path.join(DATASET_DIR, subfolder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Skipping missing folder: {folder_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nGenerating spectrograms for {label_prefix} from {folder_path}\")\n",
    "    for fname in tqdm(os.listdir(folder_path), desc=f\"Processing {label_prefix}\"):\n",
    "        if not fname.lower().endswith((\".wav\", \".mp3\", \".m4a\", \".flac\")):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(folder_path, fname)\n",
    "        counter[label_prefix] += 1\n",
    "        save_spectrogram(file_path, label_prefix, counter[label_prefix])\n",
    "\n",
    "print(f\"\\nall spectrograms saved in '{OUTPUT_DIR}/'\")\n",
    "print(f\"   PD: {counter['PD']} files\")\n",
    "print(f\"   HC: {counter['HC']} files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4799e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentation\n",
    "import os, random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "from tqdm import tqdm\n",
    "\n",
    "# directories\n",
    "SPEC_DIR = \"spectrograms_from_kotlin\"\n",
    "AUG_DIR = \"spectrograms_augmented\"\n",
    "os.makedirs(AUG_DIR, exist_ok=True)\n",
    "\n",
    "def specaugment(img, freq_mask_param=30, time_mask_param=40, num_masks=2):\n",
    "    \"\"\"Apply frequency and time masking like SpecAugment.\"\"\"\n",
    "    img_np = np.array(img)\n",
    "    h, w = img_np.shape[:2]\n",
    "    for _ in range(num_masks):\n",
    "        f = random.randint(0, freq_mask_param)\n",
    "        f0 = random.randint(0, max(1, h - f))\n",
    "        img_np[f0:f0+f, :] = img_np.mean()\n",
    "\n",
    "        t = random.randint(0, time_mask_param)\n",
    "        t0 = random.randint(0, max(1, w - t))\n",
    "        img_np[:, t0:t0+t] = img_np.mean()\n",
    "\n",
    "    return Image.fromarray(img_np.astype(np.uint8))\n",
    "\n",
    "def random_augment(img):\n",
    "    \"\"\"Apply random combination of SpecAugment + color/noise augmentations.\"\"\"\n",
    "    # SpecAugment\n",
    "    # if random.random() < 0.5:\n",
    "    #     img = specaugment(img)\n",
    "\n",
    "    #Color jitter (contrast + brightness)\n",
    "    if random.random() < 0.9:\n",
    "        enhancer = ImageEnhance.Contrast(img)\n",
    "        img = enhancer.enhance(random.uniform(0.8,1.2))\n",
    "        enhancer = ImageEnhance.Brightness(img)\n",
    "        img = enhancer.enhance(random.uniform(0.8,1.2))\n",
    "\n",
    "    # # Horizontal flip\n",
    "    # if random.random() < 0.5:\n",
    "    #     img = ImageOps.mirror(img)\n",
    "\n",
    "    #Gaussian noise\n",
    "    if random.random() < 0.9:\n",
    "        arr = np.array(img).astype(np.float32)\n",
    "        noise = np.random.normal(0, 5, arr.shape)\n",
    "        arr = np.clip(arr + noise, 0, 255)\n",
    "        img = Image.fromarray(arr.astype(np.uint8))\n",
    "\n",
    "    return img\n",
    "\n",
    "N_AUG = 2\n",
    "all_specs = [f for f in os.listdir(SPEC_DIR) if f.endswith(\".png\")]\n",
    "print(f\" Generating {N_AUG} augmented copies for {len(all_specs)} spectrograms...\")\n",
    "print(all_specs)\n",
    "\n",
    "for fname in tqdm(all_specs):\n",
    "    img_path = os.path.join(SPEC_DIR, fname)\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    if \"PD\" in fname.upper():\n",
    "        label_prefix = \"PD\"\n",
    "    elif \"HC\" in fname.upper():\n",
    "        label_prefix = \"HC\"\n",
    "    else:\n",
    "        print(\"Skipping file:\", fname)\n",
    "        continue  \n",
    "\n",
    "\n",
    "    base_name = os.path.splitext(fname)[0]\n",
    "\n",
    "    for i in range(N_AUG):\n",
    "        aug_img = random_augment(img)\n",
    "        new_name = f\"{label_prefix}_{base_name}_aug{i+1}.png\"\n",
    "        aug_img.save(os.path.join(AUG_DIR, new_name))\n",
    "\n",
    "print(f\"augmented data saved in '{AUG_DIR}/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af2d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ai model\n",
    "\n",
    "import os, numpy as np, warnings, time, random\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"GPU Configuration:\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Found: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"Using device: {device}\")\n",
    "else:\n",
    "    print(\"No GPU found. Running on CPU\")\n",
    "\n",
    "def extract_middle_segment(audio_path, duration=1.5, sr=8000):\n",
    "    \"\"\"Extract 1.5s middle voiced segment\"\"\"\n",
    "    try:\n",
    "        y, _ = librosa.load(audio_path, sr=sr, duration=10)\n",
    "        intervals = librosa.effects.split(y, top_db=30)\n",
    "        if len(intervals) == 0:\n",
    "            return None\n",
    "        voiced_parts = [y[start:end] for start, end in intervals]\n",
    "        longest = max(voiced_parts, key=len)\n",
    "        total = int(duration * sr)\n",
    "        if len(longest) < total:\n",
    "            return None\n",
    "        start = (len(longest) - total) // 2\n",
    "        return longest[start:start + total]\n",
    "    except Exception as e:\n",
    "        print(f\"{os.path.basename(audio_path)}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_mel_spectrogram(audio, sr=8000, n_mels=256, n_fft=1024, hop_length=51, save_path=None):\n",
    "    \"\"\"Create mel-scale spectrogram\"\"\"\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=audio, sr=sr, n_mels=n_mels, n_fft=n_fft,\n",
    "        hop_length=hop_length, window='hann'\n",
    "    )\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "    S_norm = (S_db - S_db.min()) / (S_db.max() - S_db.min())\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    librosa.display.specshow(S_norm, sr=sr, hop_length=hop_length, cmap='viridis')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(pad=0)\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=100, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    return save_path\n",
    "\n",
    "\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "\n",
    "\n",
    "class InceptionV3Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=2, dropout=0.2):\n",
    "        super(InceptionV3Classifier, self).__init__()\n",
    "        \n",
    "        self.inception = models.inception_v3(weights='IMAGENET1K_V1', aux_logits=True)\n",
    "        \n",
    "        for param in self.inception.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "\n",
    "        num_features = self.inception.fc.in_features\n",
    "        self.inception.fc = nn.Identity()\n",
    "        self.inception.AuxLogits.fc = nn.Identity()\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_features),\n",
    "            nn.Linear(num_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            self.inception.eval()\n",
    "        \n",
    "        x = self.inception(x)\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).long()  \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device).long()\n",
    "            logits = model(inputs)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            y_probs.extend(probs[:, 1].cpu().numpy())\n",
    "            y_pred.extend(torch.argmax(probs, dim=1).cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "    return np.array(y_true), np.array(y_pred), np.array(y_probs)\n",
    "\n",
    "\n",
    "\n",
    "DATA_DIR = \"voice_dataset\"\n",
    "SPEC_DIR = \"spectrograms_melfixed\"\n",
    "AUG_DIR = \"spectrograms_augmented\"\n",
    "os.makedirs(SPEC_DIR, exist_ok=True)\n",
    "os.makedirs(AUG_DIR, exist_ok=True)\n",
    "\n",
    "audio_paths, labels = [], []\n",
    "for folder in [\"PD_AH\", \"HC_AH\"]:\n",
    "    folder_path = os.path.join(DATA_DIR, folder)\n",
    "    if not os.path.isdir(folder_path): continue\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(\".wav\"):\n",
    "            audio_paths.append(os.path.join(folder_path, filename))\n",
    "            labels.append(1 if \"PD\" in folder else 0)\n",
    "print(f\" Found {len(audio_paths)} audio files: {sum(labels)} PD / {len(labels)-sum(labels)} HC\")\n",
    "\n",
    "print(\"\\n Loading precomputed spectrograms...\")\n",
    "spectrogram_paths, valid_labels = [], []\n",
    "for f in os.listdir(SPEC_DIR):\n",
    "    if f.endswith(\".png\"):\n",
    "        spectrogram_paths.append(os.path.join(SPEC_DIR, f))\n",
    "        valid_labels.append(1 if \"PD\" in f.upper() else 0)\n",
    "print(f\" Loaded {len(spectrogram_paths)} spectrograms from {SPEC_DIR}\")\n",
    "\n",
    "\n",
    "original_paths, original_labels = [], []\n",
    "for folder in [\"PD_AH\", \"HC_AH\"]:\n",
    "    folder_path = os.path.join(DATA_DIR, folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(\".wav\"):\n",
    "            label = 1 if \"PD\" in folder else 0\n",
    "            original_paths.append(os.path.join(folder_path, filename))\n",
    "            original_labels.append(label)\n",
    "print(f\"Original audio files: {len(original_paths)} total\")\n",
    "\n",
    "combined_paths, combined_labels = [], []\n",
    "for folder in [SPEC_DIR, AUG_DIR]:\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".png\"):\n",
    "            combined_paths.append(os.path.join(folder, file))\n",
    "            combined_labels.append(1 if \"PD\" in file.upper() else 0)\n",
    "print(f\"Combined spectrograms (orig + aug): {len(combined_paths)} total\")\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_loader = DataLoader(SpectrogramDataset(combined_paths, combined_labels, transform),\n",
    "                          batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(SpectrogramDataset(original_paths, original_labels, transform),\n",
    "                         batch_size=8, shuffle=False)\n",
    "\n",
    "print(\"\\n Running 100 iterations of 70/30 train-test split...\\n\")\n",
    "auc_scores, acc_scores, prec_scores, rec_scores, f1_scores = [], [], [], [], []\n",
    "for iteration in range(100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        combined_paths, combined_labels, test_size=0.3,\n",
    "        stratify=combined_labels, random_state=iteration\n",
    "    )\n",
    "    train_loader = DataLoader(SpectrogramDataset(X_train, y_train, transform), batch_size=8, shuffle=True)\n",
    "    test_loader = DataLoader(SpectrogramDataset(X_test, y_test, transform), batch_size=8, shuffle=False)\n",
    "    model = InceptionV3Classifier().to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_loss, best_state, patience = float('inf'), None, 0\n",
    "    for epoch in range(10):\n",
    "        loss = train_model(model, train_loader, crit, opt, device)\n",
    "        if loss < best_loss:\n",
    "            best_loss, best_state, patience = loss, model.state_dict(), 0\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= 3: break\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "    y_true, y_pred, y_prob = evaluate_model(model, test_loader, device)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc_scores.append(auc); acc_scores.append(acc)\n",
    "    prec_scores.append(prec); rec_scores.append(rec); f1_scores.append(f1)\n",
    "    print(\"we are on iteration\" + str(iteration))\n",
    "    if iteration % 10 == 0:\n",
    "        print(str(iteration) + \" results\")\n",
    "        print(f\"AUC:       {np.mean(auc_scores):.4f} Â± {np.std(auc_scores):.4f}\")\n",
    "        print(f\"Accuracy:  {np.mean(acc_scores):.4f} Â± {np.std(acc_scores):.4f}\")\n",
    "        print(f\"Precision: {np.mean(prec_scores):.4f} Â± {np.std(prec_scores):.4f}\")\n",
    "        print(f\"Recall:    {np.mean(rec_scores):.4f} Â± {np.std(rec_scores):.4f}\")\n",
    "        print(f\"F1 Score:  {np.mean(f1_scores):.4f} Â± {np.std(f1_scores):.4f}\")\n",
    "\n",
    "print(\"\\nðŸ“Š FINAL RESULTS (100 iterations)\")\n",
    "print(f\"AUC:       {np.mean(auc_scores):.4f} Â± {np.std(auc_scores):.4f}\")\n",
    "print(f\"Accuracy:  {np.mean(acc_scores):.4f} Â± {np.std(acc_scores):.4f}\")\n",
    "print(f\"Precision: {np.mean(prec_scores):.4f} Â± {np.std(prec_scores):.4f}\")\n",
    "print(f\"Recall:    {np.mean(rec_scores):.4f} Â± {np.std(rec_scores):.4f}\")\n",
    "print(f\"F1 Score:  {np.mean(f1_scores):.4f} Â± {np.std(f1_scores):.4f}\")\n",
    "\n",
    "# winning\n",
    "model.load_state_dict(best_state)\n",
    "torch.save(best_state, \"best_model. pth\")\n",
    "print(\"Saved best model weights to best_model.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae058949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = InceptionV3Classifier(num_classes=2)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", map_location=\"cpu\"))\n",
    "model.inception.aux_logits = False\n",
    "model.eval()\n",
    "\n",
    "example_input = torch.randn(1, 3, 299, 299)\n",
    "traced = torch.jit.trace(model, example_input)\n",
    "traced.save(\"best_model.pt\")\n",
    "\n",
    "print(\"Done â€” TorchScript model saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2374fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
